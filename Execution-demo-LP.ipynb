{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import argparse\n",
    "import sys\n",
    "\n",
    "from utils import seed_everything\n",
    "from dataset import get_dataset\n",
    "from community_detection import hierarchical_structure_generation\n",
    "from execution import execute_NC, execute_LP\n",
    "from preparation import LP_preparation, NC_preparation\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv = ['']  # execution on jupyter notebook\n",
    "parser = argparse.ArgumentParser()\n",
    "# general\n",
    "parser.add_argument('--task', dest='task', default='LP', type=str,\n",
    "                    help='LP; NC; Inductive')\n",
    "parser.add_argument('--mode', dest='mode', default='baseline', type=str,\n",
    "                    help='experiment mode. E.g., baseline or basemodel')\n",
    "parser.add_argument('--model', dest='model', default='GCN', type=str,\n",
    "                    help='model class name. E.g., GCN, PGNN, HCGNN...')\n",
    "parser.add_argument('--dataset', dest='dataset', default='grid', type=str,\n",
    "                    help='cora; grid; communities; ppi')\n",
    "parser.add_argument('--gpu', dest='gpu', default=True, type=bool,\n",
    "                    help='whether use gpu')\n",
    "parser.add_argument('--SEED', dest='SEED', default=123, type=int)\n",
    "\n",
    "# dataset\n",
    "parser.add_argument('--ratio_sample_pos_link', dest='ratio_sample_pos_link', default=20, type=float)\n",
    "parser.add_argument('--use_features', dest='use_features', default=True, type=bool,\n",
    "                    help='whether use node features')\n",
    "parser.add_argument('--community_detection_method', dest='community_detection_method', default='Louvain', type=str,\n",
    "                    help='community detection method, default Louvain')\n",
    "parser.add_argument('--threshold', dest='threshold', default=1, type=int,\n",
    "                    help='the threshold for graph generation, default 1')\n",
    "\n",
    "# model\n",
    "parser.add_argument('--lr', dest='lr', default=1e-2, type=float)\n",
    "parser.add_argument('--epoch_num', dest='epoch_num', default=201, type=int)\n",
    "parser.add_argument('--epoch_log', dest='epoch_log', default=10, type=int)\n",
    "parser.add_argument('--layer_num', dest='layer_num', default=2, type=int)\n",
    "parser.add_argument('--relu', dest='relu', default=True, type=bool)\n",
    "parser.add_argument('--dropout', dest='dropout', default=False, type=bool)\n",
    "parser.add_argument('--drop_ratio', dest='drop_ratio', default=0.5, type=float)\n",
    "parser.add_argument('--feature_pre', dest='feature_pre', default=True, type=bool)\n",
    "parser.add_argument('--same_level_gnn', dest='same_level_gnn', default='GCN', type=str,\n",
    "                    help='agg within level. E.g., MEAN GCN, SAGE, GAT, GIN, ...')\n",
    "parser.add_argument('--down2up_gnn', dest='down2up_gnn', default='MEAN', type=str,\n",
    "                    help='aggregation bottom-up. E.g., MEAN, GCN, SAGE, GAT, GIN, ...')\n",
    "parser.add_argument('--up2down_gnn', dest='up2down_gnn', default='GAT', type=str,\n",
    "                    help='aggregation top-down. E.g., GCN, SAGE, GAT, GIN, ...')\n",
    "parser.add_argument('--fshot', dest='fshot', default=False, type=bool)\n",
    "\n",
    "parser.set_defaults(gpu=False, task='LP', model='GCN', dataset='grid', feature_pre=True)\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(SEED=123, community_detection_method='Louvain', dataset='grid', device=device(type='cuda', index=0), down2up_gnn='MEAN', drop_ratio=0.5, dropout=True, epoch_log=10, epoch_num=501, feature_pre=True, fshot=False, gpu=True, layer_num=3, lr=0.0001, mode='basemodel', model='HCGNN', ratio_sample_pos_link=20, relu=True, same_level_gnn='GIN', task='LP', threshold=1, up2down_gnn='GAT', use_features=True) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "args.task = 'LP'\n",
    "args.dataset = 'grid'\n",
    "args.mode = 'basemodel'\n",
    "args.model = 'HCGNN'\n",
    "args.layer_num = 3\n",
    "args.epoch_num = 501\n",
    "args.lr = 0.0001\n",
    "args.relu = True\n",
    "args.dropout = True\n",
    "args.drop_ratio = 0.5\n",
    "args.same_level_gnn = 'GIN'\n",
    "args.down2up_gnn = 'MEAN'\n",
    "args.up2down_gnn = 'GAT'\n",
    "args.fshot = False\n",
    "args.SEED = 123\n",
    "args.gpu = True\n",
    "args.device = torch.device('cuda:'+str(0) if args.gpu and torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "seed_everything(args.SEED)\n",
    "\n",
    "print(args, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is reading grid dataset...\n",
      "datatset reading is done.\n",
      "Name: \n",
      "Type: Graph\n",
      "Number of nodes: 400\n",
      "Number of edges: 760\n",
      "Average degree:   3.8000\n",
      "is processing dataset...\n",
      "For graph 0, we need to collect 152 negative edges.\n",
      "Generating 0 negative instances uses 0.10 seconds.\n",
      "For graph 0, we need to remove 152 edges.\n",
      "Generating 0 positive instances uses 0.10 seconds.\n",
      "data processing is done\n",
      "is generating hierarchical structure....\n",
      "Is doing community detection....\n",
      "start 0 subgraph...\n",
      "iteration 0: from 400 items to 185 items, modularity is 0.35440426982340634.\n",
      "iteration 1: from 185 items to 58 items, modularity is 0.6974117036011082.\n",
      "iteration 2: from 58 items to 18 items, modularity is 0.8094499329120499.\n",
      "iteration 3: from 18 items to 16 items, modularity is 0.8137065010387812.\n",
      "Community detection is done\n",
      "is presenting hierarchical structure....\n",
      "start graph community 0\n",
      "layer 0: keys: [400, 584], values: [0, 399]\n",
      "layer 1: keys: [585, 642], values: [400, 584]\n",
      "layer 2: keys: [643, 660], values: [585, 642]\n",
      "layer 3: keys: [661, 676], values: [643, 660]\n",
      "Is setting up hierarchical pipelines....\n",
      "start graph 0\n",
      "Hierarchical pipelines are ready\n",
      "is recording up2down edges....\n",
      "keys in [400, 676], values in [0, 399]\n",
      "is recording down2up edges....\n",
      "keys in [0, 660], values in [400, 676]\n",
      "hierarchical structure generation is done\n",
      "is preparing datasets...\n",
      "dataset preparation is done\n",
      "data set up is done\n",
      "HCGNN(\n",
      "  (cgnn_layers): ModuleList(\n",
      "    (0): HCGNN_layer(\n",
      "      (down2up_layer): Down2Up_layer()\n",
      "      (same_level_lnn_layer): Linear(in_features=256, out_features=128, bias=True)\n",
      "      (samle_level_layer): GINConv(nn=Linear(in_features=256, out_features=128, bias=True))\n",
      "      (up2down_layer): Up2Down_layer(\n",
      "        (nn): GATConv(128, 128, heads=1)\n",
      "      )\n",
      "    )\n",
      "    (1): HCGNN_layer(\n",
      "      (down2up_layer): Down2Up_layer()\n",
      "      (same_level_lnn_layer): Linear(in_features=128, out_features=64, bias=True)\n",
      "      (samle_level_layer): GINConv(nn=Linear(in_features=128, out_features=64, bias=True))\n",
      "      (up2down_layer): Up2Down_layer(\n",
      "        (nn): GATConv(64, 64, heads=1)\n",
      "      )\n",
      "    )\n",
      "    (2): HCGNN_layer(\n",
      "      (down2up_layer): Down2Up_layer()\n",
      "      (same_level_lnn_layer): Linear(in_features=64, out_features=32, bias=True)\n",
      "      (samle_level_layer): GINConv(nn=Linear(in_features=64, out_features=32, bias=True))\n",
      "      (up2down_layer): Up2Down_layer(\n",
      "        (nn): GATConv(32, 32, heads=1)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (linear_pre): Linear(in_features=400, out_features=256, bias=True)\n",
      ")\n",
      "Epoch 0 starts !\n",
      "--------------------------------------------------------------------------------\n",
      "Evaluating Epoch 0, time 2.035, ROC-AUC: Train = 0.9864, Valid = 0.8264, Test = 0.8871\n",
      "Best valid performance is 0.8264, best test performance is 0.8871 and epoch_id is 0\n",
      "Epoch 10 starts !\n",
      "--------------------------------------------------------------------------------\n",
      "Evaluating Epoch 10, time 0.081, ROC-AUC: Train = 0.9870, Valid = 0.8284, Test = 0.9020\n",
      "Best valid performance is 0.8284, best test performance is 0.9020 and epoch_id is 10\n",
      "Epoch 20 starts !\n",
      "--------------------------------------------------------------------------------\n",
      "Evaluating Epoch 20, time 0.085, ROC-AUC: Train = 0.9869, Valid = 0.8354, Test = 0.9212\n",
      "Best valid performance is 0.8354, best test performance is 0.9212 and epoch_id is 20\n",
      "Epoch 30 starts !\n",
      "--------------------------------------------------------------------------------\n",
      "Evaluating Epoch 30, time 0.087, ROC-AUC: Train = 0.9841, Valid = 0.8284, Test = 0.9254\n",
      "Best valid performance is 0.8354, best test performance is 0.9212 and epoch_id is 20\n",
      "Epoch 40 starts !\n",
      "--------------------------------------------------------------------------------\n",
      "Evaluating Epoch 40, time 0.081, ROC-AUC: Train = 0.9806, Valid = 0.8369, Test = 0.9098\n",
      "Best valid performance is 0.8369, best test performance is 0.9098 and epoch_id is 40\n",
      "Epoch 50 starts !\n",
      "--------------------------------------------------------------------------------\n",
      "Evaluating Epoch 50, time 0.082, ROC-AUC: Train = 0.9785, Valid = 0.8411, Test = 0.9153\n",
      "Best valid performance is 0.8411, best test performance is 0.9153 and epoch_id is 50\n",
      "Epoch 60 starts !\n",
      "--------------------------------------------------------------------------------\n",
      "Evaluating Epoch 60, time 0.085, ROC-AUC: Train = 0.9767, Valid = 0.8416, Test = 0.9063\n",
      "Best valid performance is 0.8416, best test performance is 0.9063 and epoch_id is 60\n",
      "Epoch 70 starts !\n",
      "--------------------------------------------------------------------------------\n",
      "Evaluating Epoch 70, time 0.081, ROC-AUC: Train = 0.9764, Valid = 0.8373, Test = 0.9039\n",
      "Best valid performance is 0.8416, best test performance is 0.9063 and epoch_id is 60\n",
      "Epoch 80 starts !\n",
      "--------------------------------------------------------------------------------\n",
      "Evaluating Epoch 80, time 0.101, ROC-AUC: Train = 0.9769, Valid = 0.8461, Test = 0.9072\n",
      "Best valid performance is 0.8461, best test performance is 0.9072 and epoch_id is 80\n",
      "Epoch 90 starts !\n",
      "--------------------------------------------------------------------------------\n",
      "Evaluating Epoch 90, time 0.080, ROC-AUC: Train = 0.9769, Valid = 0.8485, Test = 0.9041\n",
      "Best valid performance is 0.8485, best test performance is 0.9041 and epoch_id is 90\n",
      "Epoch 100 starts !\n",
      "--------------------------------------------------------------------------------\n",
      "Evaluating Epoch 100, time 0.075, ROC-AUC: Train = 0.9765, Valid = 0.8527, Test = 0.9079\n",
      "Best valid performance is 0.8527, best test performance is 0.9079 and epoch_id is 100\n",
      "Epoch 110 starts !\n",
      "--------------------------------------------------------------------------------\n",
      "Evaluating Epoch 110, time 0.077, ROC-AUC: Train = 0.9762, Valid = 0.8495, Test = 0.9030\n",
      "Best valid performance is 0.8527, best test performance is 0.9079 and epoch_id is 100\n",
      "Epoch 120 starts !\n",
      "--------------------------------------------------------------------------------\n",
      "Evaluating Epoch 120, time 0.073, ROC-AUC: Train = 0.9756, Valid = 0.8523, Test = 0.9098\n",
      "Best valid performance is 0.8527, best test performance is 0.9079 and epoch_id is 100\n",
      "Epoch 130 starts !\n",
      "--------------------------------------------------------------------------------\n",
      "Evaluating Epoch 130, time 0.073, ROC-AUC: Train = 0.9761, Valid = 0.8513, Test = 0.9025\n",
      "Best valid performance is 0.8527, best test performance is 0.9079 and epoch_id is 100\n",
      "Epoch 140 starts !\n",
      "--------------------------------------------------------------------------------\n",
      "Evaluating Epoch 140, time 0.069, ROC-AUC: Train = 0.9753, Valid = 0.8526, Test = 0.9060\n",
      "Best valid performance is 0.8527, best test performance is 0.9079 and epoch_id is 100\n",
      "Epoch 150 starts !\n",
      "--------------------------------------------------------------------------------\n",
      "Evaluating Epoch 150, time 0.080, ROC-AUC: Train = 0.9761, Valid = 0.8464, Test = 0.8913\n",
      "Best valid performance is 0.8527, best test performance is 0.9079 and epoch_id is 100\n",
      "Epoch 160 starts !\n",
      "--------------------------------------------------------------------------------\n",
      "Evaluating Epoch 160, time 0.079, ROC-AUC: Train = 0.9749, Valid = 0.8511, Test = 0.9032\n",
      "Best valid performance is 0.8527, best test performance is 0.9079 and epoch_id is 100\n",
      "Epoch 170 starts !\n",
      "--------------------------------------------------------------------------------\n",
      "Evaluating Epoch 170, time 0.081, ROC-AUC: Train = 0.9751, Valid = 0.8499, Test = 0.8991\n",
      "Best valid performance is 0.8527, best test performance is 0.9079 and epoch_id is 100\n",
      "Epoch 180 starts !\n",
      "--------------------------------------------------------------------------------\n",
      "Evaluating Epoch 180, time 0.081, ROC-AUC: Train = 0.9764, Valid = 0.8502, Test = 0.8999\n",
      "Best valid performance is 0.8527, best test performance is 0.9079 and epoch_id is 100\n",
      "Epoch 190 starts !\n",
      "--------------------------------------------------------------------------------\n",
      "Evaluating Epoch 190, time 0.088, ROC-AUC: Train = 0.9754, Valid = 0.8551, Test = 0.9037\n",
      "Best valid performance is 0.8551, best test performance is 0.9037 and epoch_id is 190\n",
      "Epoch 200 starts !\n",
      "--------------------------------------------------------------------------------\n",
      "Evaluating Epoch 200, time 0.080, ROC-AUC: Train = 0.9766, Valid = 0.8542, Test = 0.9025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best valid performance is 0.8551, best test performance is 0.9037 and epoch_id is 190\n",
      "Epoch 210 starts !\n",
      "--------------------------------------------------------------------------------\n",
      "Evaluating Epoch 210, time 0.084, ROC-AUC: Train = 0.9761, Valid = 0.8565, Test = 0.9055\n",
      "Best valid performance is 0.8565, best test performance is 0.9055 and epoch_id is 210\n",
      "Epoch 220 starts !\n",
      "--------------------------------------------------------------------------------\n",
      "Evaluating Epoch 220, time 0.082, ROC-AUC: Train = 0.9776, Valid = 0.8553, Test = 0.9034\n",
      "Best valid performance is 0.8565, best test performance is 0.9055 and epoch_id is 210\n",
      "Epoch 230 starts !\n",
      "--------------------------------------------------------------------------------\n",
      "Evaluating Epoch 230, time 0.084, ROC-AUC: Train = 0.9760, Valid = 0.8592, Test = 0.9067\n",
      "Best valid performance is 0.8592, best test performance is 0.9067 and epoch_id is 230\n",
      "Epoch 240 starts !\n",
      "--------------------------------------------------------------------------------\n",
      "Evaluating Epoch 240, time 0.075, ROC-AUC: Train = 0.9775, Valid = 0.8625, Test = 0.9081\n",
      "Best valid performance is 0.8625, best test performance is 0.9081 and epoch_id is 240\n",
      "Epoch 250 starts !\n",
      "--------------------------------------------------------------------------------\n",
      "Evaluating Epoch 250, time 0.081, ROC-AUC: Train = 0.9780, Valid = 0.8657, Test = 0.9077\n",
      "Best valid performance is 0.8657, best test performance is 0.9077 and epoch_id is 250\n",
      "Epoch 260 starts !\n",
      "--------------------------------------------------------------------------------\n",
      "Evaluating Epoch 260, time 0.097, ROC-AUC: Train = 0.9784, Valid = 0.8617, Test = 0.9062\n",
      "Best valid performance is 0.8657, best test performance is 0.9077 and epoch_id is 250\n",
      "Epoch 270 starts !\n",
      "--------------------------------------------------------------------------------\n",
      "Evaluating Epoch 270, time 0.124, ROC-AUC: Train = 0.9782, Valid = 0.8658, Test = 0.9065\n",
      "Best valid performance is 0.8658, best test performance is 0.9065 and epoch_id is 270\n",
      "Epoch 280 starts !\n",
      "--------------------------------------------------------------------------------\n",
      "Evaluating Epoch 280, time 0.126, ROC-AUC: Train = 0.9776, Valid = 0.8653, Test = 0.9093\n",
      "Best valid performance is 0.8658, best test performance is 0.9065 and epoch_id is 270\n",
      "Epoch 290 starts !\n",
      "--------------------------------------------------------------------------------\n",
      "Evaluating Epoch 290, time 0.124, ROC-AUC: Train = 0.9783, Valid = 0.8657, Test = 0.9058\n",
      "Best valid performance is 0.8658, best test performance is 0.9065 and epoch_id is 270\n",
      "Epoch 300 starts !\n",
      "--------------------------------------------------------------------------------\n",
      "Evaluating Epoch 300, time 0.121, ROC-AUC: Train = 0.9782, Valid = 0.8513, Test = 0.9006\n",
      "Best valid performance is 0.8658, best test performance is 0.9065 and epoch_id is 270\n",
      "Epoch 310 starts !\n",
      "--------------------------------------------------------------------------------\n",
      "Evaluating Epoch 310, time 0.110, ROC-AUC: Train = 0.9780, Valid = 0.8622, Test = 0.9043\n",
      "Best valid performance is 0.8658, best test performance is 0.9065 and epoch_id is 270\n",
      "Epoch 320 starts !\n",
      "--------------------------------------------------------------------------------\n",
      "Evaluating Epoch 320, time 0.111, ROC-AUC: Train = 0.9778, Valid = 0.8629, Test = 0.9093\n",
      "Best valid performance is 0.8658, best test performance is 0.9065 and epoch_id is 270\n",
      "Epoch 330 starts !\n",
      "--------------------------------------------------------------------------------\n",
      "Evaluating Epoch 330, time 0.114, ROC-AUC: Train = 0.9772, Valid = 0.8634, Test = 0.9098\n",
      "Best valid performance is 0.8658, best test performance is 0.9065 and epoch_id is 270\n",
      "Epoch 340 starts !\n",
      "--------------------------------------------------------------------------------\n",
      "Evaluating Epoch 340, time 0.100, ROC-AUC: Train = 0.9771, Valid = 0.8596, Test = 0.8999\n",
      "Best valid performance is 0.8658, best test performance is 0.9065 and epoch_id is 270\n",
      "Epoch 350 starts !\n",
      "--------------------------------------------------------------------------------\n",
      "Evaluating Epoch 350, time 0.113, ROC-AUC: Train = 0.9776, Valid = 0.8594, Test = 0.8956\n",
      "Best valid performance is 0.8658, best test performance is 0.9065 and epoch_id is 270\n",
      "Epoch 360 starts !\n",
      "--------------------------------------------------------------------------------\n",
      "Evaluating Epoch 360, time 0.122, ROC-AUC: Train = 0.9773, Valid = 0.8598, Test = 0.9030\n",
      "Best valid performance is 0.8658, best test performance is 0.9065 and epoch_id is 270\n",
      "Epoch 370 starts !\n",
      "--------------------------------------------------------------------------------\n",
      "Evaluating Epoch 370, time 0.121, ROC-AUC: Train = 0.9768, Valid = 0.8535, Test = 0.8875\n",
      "Best valid performance is 0.8658, best test performance is 0.9065 and epoch_id is 270\n",
      "Epoch 380 starts !\n",
      "--------------------------------------------------------------------------------\n",
      "Evaluating Epoch 380, time 0.124, ROC-AUC: Train = 0.9766, Valid = 0.8586, Test = 0.8894\n",
      "Best valid performance is 0.8658, best test performance is 0.9065 and epoch_id is 270\n",
      "Epoch 390 starts !\n",
      "--------------------------------------------------------------------------------\n",
      "Evaluating Epoch 390, time 0.118, ROC-AUC: Train = 0.9771, Valid = 0.8580, Test = 0.8999\n",
      "Best valid performance is 0.8658, best test performance is 0.9065 and epoch_id is 270\n",
      "Epoch 400 starts !\n",
      "--------------------------------------------------------------------------------\n",
      "Evaluating Epoch 400, time 0.148, ROC-AUC: Train = 0.9766, Valid = 0.8572, Test = 0.8975\n",
      "Best valid performance is 0.8658, best test performance is 0.9065 and epoch_id is 270\n",
      "Epoch 410 starts !\n",
      "--------------------------------------------------------------------------------\n",
      "Evaluating Epoch 410, time 0.136, ROC-AUC: Train = 0.9765, Valid = 0.8575, Test = 0.8906\n",
      "Best valid performance is 0.8658, best test performance is 0.9065 and epoch_id is 270\n",
      "Epoch 420 starts !\n",
      "--------------------------------------------------------------------------------\n",
      "Evaluating Epoch 420, time 0.145, ROC-AUC: Train = 0.9763, Valid = 0.8565, Test = 0.8991\n",
      "Best valid performance is 0.8658, best test performance is 0.9065 and epoch_id is 270\n",
      "Epoch 430 starts !\n",
      "--------------------------------------------------------------------------------\n",
      "Evaluating Epoch 430, time 0.127, ROC-AUC: Train = 0.9764, Valid = 0.8546, Test = 0.8935\n",
      "Best valid performance is 0.8658, best test performance is 0.9065 and epoch_id is 270\n",
      "Epoch 440 starts !\n",
      "--------------------------------------------------------------------------------\n",
      "Evaluating Epoch 440, time 0.128, ROC-AUC: Train = 0.9767, Valid = 0.8546, Test = 0.8857\n",
      "Best valid performance is 0.8658, best test performance is 0.9065 and epoch_id is 270\n",
      "Epoch 450 starts !\n",
      "--------------------------------------------------------------------------------\n",
      "Evaluating Epoch 450, time 0.109, ROC-AUC: Train = 0.9773, Valid = 0.8541, Test = 0.8911\n",
      "Best valid performance is 0.8658, best test performance is 0.9065 and epoch_id is 270\n",
      "Epoch 460 starts !\n",
      "--------------------------------------------------------------------------------\n",
      "Evaluating Epoch 460, time 0.131, ROC-AUC: Train = 0.9768, Valid = 0.8537, Test = 0.8880\n",
      "Best valid performance is 0.8658, best test performance is 0.9065 and epoch_id is 270\n",
      "Epoch 470 starts !\n",
      "--------------------------------------------------------------------------------\n",
      "Evaluating Epoch 470, time 0.110, ROC-AUC: Train = 0.9763, Valid = 0.8544, Test = 0.8935\n",
      "Best valid performance is 0.8658, best test performance is 0.9065 and epoch_id is 270\n",
      "Epoch 480 starts !\n",
      "--------------------------------------------------------------------------------\n",
      "Evaluating Epoch 480, time 0.136, ROC-AUC: Train = 0.9769, Valid = 0.8473, Test = 0.8838\n",
      "Best valid performance is 0.8658, best test performance is 0.9065 and epoch_id is 270\n",
      "Epoch 490 starts !\n",
      "--------------------------------------------------------------------------------\n",
      "Evaluating Epoch 490, time 0.107, ROC-AUC: Train = 0.9770, Valid = 0.8470, Test = 0.8847\n",
      "Best valid performance is 0.8658, best test performance is 0.9065 and epoch_id is 270\n",
      "Epoch 500 starts !\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 500, time 0.127, ROC-AUC: Train = 0.9768, Valid = 0.8497, Test = 0.8852\n",
      "Best valid performance is 0.8658, best test performance is 0.9065 and epoch_id is 270\n"
     ]
    }
   ],
   "source": [
    "ls_df_friends, graphs_complete, graphs, ls_valid_edges, ls_test_edges, features, df_labels = get_dataset(\n",
    "    dataset_name=args.dataset,\n",
    "    use_features=args.use_features,\n",
    "    task=args.task,\n",
    "    ratio_sample=args.ratio_sample_pos_link\n",
    ")\n",
    "ls_hierarchical_community, ls_up2down_edges, ls_down2up_edges = hierarchical_structure_generation(\n",
    "    dataset_name=args.dataset,\n",
    "    graphs=graphs,\n",
    "    method=args.community_detection_method,\n",
    "    threshold=args.threshold\n",
    ")\n",
    "ls_adj_same_level, ls_df_train, ls_df_valid, ls_df_test = LP_preparation(\n",
    "    graphs=graphs,\n",
    "    ls_df_friends=ls_df_friends,\n",
    "    ls_test_edges=ls_test_edges,\n",
    "    ls_valid_edges=ls_valid_edges,\n",
    "    ls_hierarchical_community=ls_hierarchical_community\n",
    ")\n",
    "execute_LP(\n",
    "    args, graphs, features, ls_hierarchical_community,\n",
    "    ls_adj_same_level, ls_up2down_edges, ls_down2up_edges,\n",
    "    ls_df_train, ls_df_valid, ls_df_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
